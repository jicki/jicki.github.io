<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=x-ua-compatible content="IE=edge, chrome=1"><title>docker k8s 1.3.8 + flannel - 小炒肉</title><meta name=Description content="docker k8s 1.3.8 + flannel"><meta property="og:title" content="docker k8s 1.3.8 + flannel"><meta property="og:description" content="docker k8s 1.3.8 + flannel"><meta property="og:type" content="article"><meta property="og:url" content="https://jicki.cn/kubernetes-1.3.8/"><meta property="og:image" content="https://jicki.cn/logo.png"><meta property="article:published_time" content="2016-10-12T00:00:00+00:00"><meta property="article:modified_time" content="2016-10-12T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jicki.cn/logo.png"><meta name=twitter:title content="docker k8s 1.3.8 + flannel"><meta name=twitter:description content="docker k8s 1.3.8 + flannel"><meta name=application-name content="小炒肉"><meta name=apple-mobile-web-app-title content="小炒肉"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=/images/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://jicki.cn/kubernetes-1.3.8/><link rel=prev href=https://jicki.cn/glusterfs/><link rel=next href=https://jicki.cn/kubernetes-1.4.0/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"docker k8s 1.3.8 + flannel","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/jicki.cn\/kubernetes-1.3.8\/"},"genre":"posts","wordcount":2312,"url":"https:\/\/jicki.cn\/kubernetes-1.3.8\/","datePublished":"2016-10-12T00:00:00+00:00","dateModified":"2016-10-12T00:00:00+00:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"小炒肉"},"description":"docker k8s 1.3.8 + flannel"}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':('auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark'))&&document.body.setAttribute('theme','dark');</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=小炒肉>小炒肉</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/about/>关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i></span></span><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=小炒肉>小炒肉</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></div><a class=menu-item href=/posts/>文章</a><a class=menu-item href=/tags/>标签</a><a class=menu-item href=/categories/>分类</a><a class=menu-item href=/about/>关于</a><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>目录</h2><div class="toc-content always-active" id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animated flipInX">docker k8s 1.3.8 + flannel</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://jicki.cn title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>小炒肉</a></span>&nbsp;<span class=post-category>收录于 <a href=/categories/kubernetes/><i class="far fa-folder fa-fw"></i>kubernetes</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2016-10-12>2016-10-12</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 2312 字&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 5 分钟&nbsp;<span id=/kubernetes-1.3.8/ class=leancloud_visitors data-flag-title="docker k8s 1.3.8 + flannel">
<i class="far fa-eye fa-fw"></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;次阅读
</span>&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#说明>说明</a></li><li><a href=#环境说明>环境说明</a></li><li><a href=#初始化环境>初始化环境</a></li><li><a href=#安装-etcd-集群>安装 etcd 集群</a></li><li><a href=#flannel-网络>flannel 网络</a></li></ul><ul><li><a href=#下载-rpm-包>下载 rpm 包</a></li><li><a href=#配置-apiserver>配置 apiserver</a></li><li><a href=#启动-所有服务>启动 所有服务</a></li><li><a href=#node-配置-kubelet>node 配置 kubelet</a></li><li><a href=#node-配置-k8s-config>node 配置 k8s config</a></li><li><a href=#node-启动-所有服务>node 启动 所有服务</a></li><li><a href=#测试>测试</a></li></ul><ul><li><a href=#创建-ca-证书>创建 ca 证书</a></li><li><a href=#配置-apiserver-证书>配置 apiserver 证书</a></li><li><a href=#签署-apiserver-证书>签署 apiserver 证书</a></li><li><a href=#生成-node-证书>生成 node 证书</a></li><li><a href=#生成集群管理证书>生成集群管理证书</a></li><li><a href=#apiserver-配置>apiserver 配置</a></li><li><a href=#controller-manager-配置>controller manager 配置</a></li><li><a href=#重启-所有服务>重启 所有服务</a></li><li><a href=#node-节点配置>node 节点配置</a></li><li><a href=#node-节点-kubelet-配置>node 节点 kubelet 配置</a></li><li><a href=#node-节点-config-配置>node 节点 config 配置</a></li><li><a href=#node-创建-kube-proxy>node 创建 kube-proxy</a></li><li><a href=#node-节点-配置-kube-proxy-证书>node 节点 配置 kube-proxy 证书</a></li><li><a href=#node节点重启服务>node节点重启服务</a></li></ul></nav></div></div><div class=content id=content><h1 id=docker-k8s--flannel>docker k8s + flannel</h1><h2 id=说明>说明</h2><p>kubernetes 是谷歌开源的 docker 集群管理解决方案。</p><p>项目地址：
<a href=http://kubernetes.io/>http://kubernetes.io/</a></p><h2 id=环境说明>环境说明</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>node-1: 10.6.0.140
node-2: 10.6.0.187
node-3: 10.6.0.188
</code></pre></td></tr></table></div></div><p>kubernetes 集群，包含 master 节点，与 node 节点。</p><h2 id=初始化环境>初始化环境</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>hostnamectl --static set-hostname hostname

10.6.0.140 - k8s-master
10.6.0.187 - k8s-node-1
10.6.0.188 - k8s-node-2
</code></pre></td></tr></table></div></div><p>编辑 /etc/hosts 文件，配置hostname 通信</p><p>vi /etc/hosts 添加:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>10.6.0.140 k8s-master
10.6.0.187 k8s-node-1
10.6.0.188 k8s-node-2
</code></pre></td></tr></table></div></div><h2 id=安装-etcd-集群>安装 etcd 集群</h2><p>etcd 是k8s集群的基础组件。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>yum -y install etcd
</code></pre></td></tr></table></div></div><p>修改配置文件，/etc/etcd/etcd.conf 需要修改如下参数：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>ETCD_NAME=etcd1
ETCD_DATA_DIR=&#34;/var/lib/etcd/etcd1.etcd&#34;
ETCD_LISTEN_PEER_URLS=&#34;http://10.6.0.140:2380&#34;
ETCD_LISTEN_CLIENT_URLS=&#34;http://10.6.0.140:2379,http://127.0.0.1:2379&#34;
ETCD_INITIAL_ADVERTISE_PEER_URLS=&#34;http://10.6.0.140:2380&#34;
ETCD_INITIAL_CLUSTER=&#34;etcd1=http://10.6.0.140:2380,etcd2=http://10.6.0.187:2380,etcd3=http://10.6.0.188:2380&#34;
ETCD_INITIAL_CLUSTER_STATE=&#34;new&#34;
ETCD_INITIAL_CLUSTER_TOKEN=&#34;k8s-etcd-cluster&#34;
ETCD_ADVERTISE_CLIENT_URLS=&#34;http://10.6.0.140:2379&#34;
</code></pre></td></tr></table></div></div><p>其他etcd集群中： ETCD_NAME , 以及IP 需要变动</p><p>修改 etcd 启动文件 /usr/lib/systemd/system/etcd.service</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>sed -i &#39;s/\\\&#34;${ETCD_LISTEN_CLIENT_URLS}\\\&#34;/\\\&#34;${ETCD_LISTEN_CLIENT_URLS}\\\&#34; --listen-client-urls=\\\&#34;${ETCD_LISTEN_CLIENT_URLS}\\\&#34; --advertise-client-urls=\\\&#34;${ETCD_ADVERTISE_CLIENT_URLS}\\\&#34; --initial-cluster-token=\\\&#34;${ETCD_INITIAL_CLUSTER_TOKEN}\\\&#34; --initial-cluster=\\\&#34;${ETCD_INITIAL_CLUSTER}\\\&#34; --initial-cluster-state=\\\&#34;${ETCD_INITIAL_CLUSTER_STATE}\\\&#34;/g&#39; /usr/lib/systemd/system/etcd.service
</code></pre></td></tr></table></div></div><p>分别启动 所有节点的 etcd 服务</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>systemctl enable etcd

systemctl start etcd

systemctl status etcd
</code></pre></td></tr></table></div></div><p>查看 etcd 集群状态：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>etcdctl cluster-health
</code></pre></td></tr></table></div></div><p>出现 cluster is healthy 表示成功</p><p>查看 etcd 集群成员：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>etcdctl member list
</code></pre></td></tr></table></div></div><h2 id=flannel-网络>flannel 网络</h2><p>安装 flannel</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>yum -y install flannel
</code></pre></td></tr></table></div></div><p>清除网络中遗留的docker 网络 (docker0, flannel0 等)</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>ifconfig
</code></pre></td></tr></table></div></div><p>如果存在 请删除之，以免发生不必要的未知错误</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>ip link delete docker0
....
</code></pre></td></tr></table></div></div><p>设置 flannel 所用到的IP段</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>etcdctl --endpoint http://10.6.0.140:2379 set /flannel/network/config &#39;{&#34;Network&#34;:&#34;10.10.0.0/16&#34;,&#34;SubnetLen&#34;:25,&#34;Backend&#34;:{&#34;Type&#34;:&#34;vxlan&#34;,&#34;VNI&#34;:1}}&#39;
</code></pre></td></tr></table></div></div><p>接下来修改 flannel 配置文件</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim /etc/sysconfig/flanneld


FLANNEL_ETCD=&#34;http://10.6.0.140:2379,http://10.6.0.187:2379,http://10.6.0.188:2379&#34;   # 修改为 集群地址
FLANNEL_ETCD_KEY=&#34;/flannel/network/config&#34;        # 修改为 上面导入配置中的  /flannel/network
FLANNEL_OPTIONS=&#34;--iface=em1&#34;                     # 修改为 本机物理网卡的名称
</code></pre></td></tr></table></div></div><p>启动 flannel</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>systemctl enable flanneld
systemctl start flanneld
systemctl status flanneld
</code></pre></td></tr></table></div></div><p>下面还需要修改 docker 的启动文件 /usr/lib/systemd/system/docker.service</p><p>在 ExecStart 参数 dockerd 后面增加</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>ExecStart=/usr/bin/dockerd $DOCKER_NETWORK_OPTIONS
</code></pre></td></tr></table></div></div><p>重新读取配置，启动 docker</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>systemctl daemon-reload
systemctl start docker
</code></pre></td></tr></table></div></div><p>查看网络接管</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>ifconfig
</code></pre></td></tr></table></div></div><p>可以看到 docker0 与 flannel.1 已经在我们设置的IP段内了，表示已经成功</p><h1 id=安装-kubernetes>安装 kubernetes</h1><p>安装k8s 首先是 Master 端安装</p><h2 id=下载-rpm-包>下载 rpm 包</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>http://upyun.mritd.me/kubernetes/kubernetes-1.3.8-1.x86_64.rpm
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>rpm -ivh kubernetes-1.3.8-1.x86_64.rpm
</code></pre></td></tr></table></div></div><p>安装完 kubernetes 以后</p><h2 id=配置-apiserver>配置 apiserver</h2><p>编辑配置文件</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim /etc/kubernetes/apiserver


###
# kubernetes system config
#
# The following values are used to configure the kube-apiserver
#

# The address on the local server to listen to.
KUBE_API_ADDRESS=&#34;--insecure-bind-address=10.6.0.140&#34;

# The port on the local server to listen on.
KUBE_API_PORT=&#34;--port=8080&#34;

# Port minions listen on
KUBELET_PORT=&#34;--kubelet-port=10250&#34;

# Comma separated list of nodes in the etcd cluster
KUBE_ETCD_SERVERS=&#34;--etcd-servers=http://10.6.0.140:2379,http://10.6.0.187:2379,http://10.6.0.188:2379&#34;

# Address range to use for services
KUBE_SERVICE_ADDRESSES=&#34;--service-cluster-ip-range=10.254.0.0/16&#34;

# default admission control policies
KUBE_ADMISSION_CONTROL=&#34;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota&#34;

# Add your own!
KUBE_API_ARGS=&#34;&#34;
</code></pre></td></tr></table></div></div><h2 id=启动-所有服务>启动 所有服务</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>systemctl start kube-apiserver
systemctl start kube-controller-manager
systemctl start kube-scheduler
systemctl enable kube-apiserver
systemctl enable kube-controller-manager
systemctl enable kube-scheduler
systemctl status kube-apiserver
systemctl status kube-controller-manager
systemctl status kube-scheduler
</code></pre></td></tr></table></div></div><p>node 端安装</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>wget http://upyun.mritd.me/kubernetes/kubernetes-1.3.8-1.x86_64.rpm

rpm -ivh kubernetes-1.3.8-1.x86_64.rpm
</code></pre></td></tr></table></div></div><h2 id=node-配置-kubelet>node 配置 kubelet</h2><p>编辑配置文件</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim /etc/kubernetes/kubelet


###
# kubernetes kubelet (minion) config

# The address for the info server to serve on (set to 0.0.0.0 or &#34;&#34; for all interfaces)
KUBELET_ADDRESS=&#34;--address=10.6.0.187&#34;

# The port for the info server to serve on
KUBELET_PORT=&#34;--port=10250&#34;

# You may leave this blank to use the actual hostname
KUBELET_HOSTNAME=&#34;--hostname-override=k8s-node-1&#34;

# location of the api-server
KUBELET_API_SERVER=&#34;--api-servers=http://10.6.0.140:8080&#34;

# Add your own!
KUBELET_ARGS=&#34;--pod-infra-container-image=docker.io/kubernetes/pause:latest&#34;
</code></pre></td></tr></table></div></div><p>注： KUBELET_HOSTNAME 这个配置中 配置的为 hostname 名称，主要用于区分 node 在集群中的显示
名称 必须能 ping 通，所以前面在 /etc/hosts 中要做配置</p><h2 id=node-配置-k8s-config>node 配置 k8s config</h2><p>下面修改 kubernetes 的 config 文件</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim /etc/kubernetes/config


###
# kubernetes system config
#
# The following values are used to configure various aspects of all
# kubernetes services, including
#
#   kube-apiserver.service
#   kube-controller-manager.service
#   kube-scheduler.service
#   kubelet.service
#   kube-proxy.service
# logging to stderr means we get it in the systemd journal
KUBE_LOGTOSTDERR=&#34;--logtostderr=true&#34;

# journal message level, 0 is debug
KUBE_LOG_LEVEL=&#34;--v=0&#34;

# Should this cluster be allowed to run privileged docker containers
KUBE_ALLOW_PRIV=&#34;--allow-privileged=false&#34;

# How the controller-manager, scheduler, and proxy find the apiserver
KUBE_MASTER=&#34;--master=http://10.6.0.140:8080&#34;
</code></pre></td></tr></table></div></div><h2 id=node-启动-所有服务>node 启动 所有服务</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>systemctl start kubelet
systemctl start kube-proxy
systemctl enable kubelet
systemctl enable kube-proxy
systemctl status kubelet
systemctl status kube-proxy
</code></pre></td></tr></table></div></div><h2 id=测试>测试</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>[root@k8s-master ~]#kubectl --server=&#34;http://10.6.0.140:8080&#34; get node
NAME         STATUS     AGE
k8s-master   NotReady   50m
k8s-node-1   Ready      1m
k8s-node-2   Ready      57s
</code></pre></td></tr></table></div></div><h1 id=双向-tls-认证配置>双向 TLS 认证配置</h1><p>kubernetes 提供了多种安全认证机制 Token 或用户名密码的单向 tls 认证, 基于 CA 证书 双向 tls 认证。</p><h2 id=创建-ca-证书>创建 ca 证书</h2><p>master 中 创建 openssl ca 证书</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>mkdir /etc/kubernetes/cert

# 必须授权

chown kube:kube -R /etc/kubernetes/cert

cd /etc/kubernetes/cert

# 生成私钥

openssl genrsa -out k8sca-key.pem 2048

openssl req -x509 -new -nodes -key k8sca-key.pem -days 10000 -out k8sca.pem -subj &#34;/CN=kube-ca&#34;
</code></pre></td></tr></table></div></div><h2 id=配置-apiserver-证书>配置 apiserver 证书</h2><p>复制openssl 的配置文件到cert目录中</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>cp /etc/pki/tls/openssl.cnf .
</code></pre></td></tr></table></div></div><p>编辑 配置文件，支持IP认证</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim openssl.cnf


# 在 distinguished_name 上面添加  req_extensions          = v3_req

[ req ]
.....
req_extensions          = v3_req
distinguished_name      = req_distinguished_name
.....


# 在 [ v3_req ]  下面添加  subjectAltName = @alt_names

[ v3_req ]

basicConstraints = CA:FALSE
keyUsage = nonRepudiation, digitalSignature, keyEncipherment
subjectAltName = @alt_names


## 添加 如下所有内容

[ alt_names ]
DNS.1 = kubernetes
DNS.2 = kubernetes.default
DNS.3 = kubernetes.default.svc
DNS.4 = kubernetes.default.svc.cluster.local
IP.1 = ${K8S_SERVICE_IP}  # kubernetes server ip
IP.2 = ${MASTER_HOST}     # master ip(如果都在一台机器上写一个就行)
</code></pre></td></tr></table></div></div><h2 id=签署-apiserver-证书>签署 apiserver 证书</h2><p>然后开始签署 apiserver 相关的证书</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>openssl genrsa -out apiserver-key.pem 2048

openssl req -new -key apiserver-key.pem -out apiserver.csr -subj &#34;/CN=kube-apiserver&#34; -config openssl.cnf

openssl x509 -req -in apiserver.csr -CA k8sca.pem -CAkey k8sca-key.pem -CAcreateserial -out apiserver.pem -days 365 -extensions v3_req -extfile openssl.cnf
</code></pre></td></tr></table></div></div><h2 id=生成-node-证书>生成 node 证书</h2><p>下面 生成 每个 node 的证书, 在 master 中生成，然后复制到各 node 中</p><p>apiserver 证书签署完成后还需要签署每个节点 node 的证书</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>cp openssl.cnf worker-openssl.cnf
</code></pre></td></tr></table></div></div><p>编辑配置文件:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim worker-openssl.cnf

## 主要修改如下[ alt_names ]内容 , 有多少个node 就写多少个IP配置：

[ alt_names ]
IP.1 = 10.6.0.187
IP.2 = 10.6.0.188
</code></pre></td></tr></table></div></div><p>生成 k8s-node-1 私钥</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>openssl genrsa -out k8s-node-1-worker-key.pem 2048

openssl req -new -key k8s-node-1-worker-key.pem -out k8s-node-1-worker.csr -subj &#34;/CN=k8s-node-1&#34; -config worker-openssl.cnf

openssl x509 -req -in k8s-node-1-worker.csr -CA k8sca.pem -CAkey k8sca-key.pem -CAcreateserial -out k8s-node-1-worker.pem -days 365 -extensions v3_req -extfile worker-openssl.cnf
</code></pre></td></tr></table></div></div><p>生成 k8s-node-2 私钥</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>openssl genrsa -out k8s-node-2-worker-key.pem 2048

openssl req -new -key k8s-node-2-worker-key.pem -out k8s-node-2-worker.csr -subj &#34;/CN=k8s-node-2&#34; -config worker-openssl.cnf

openssl x509 -req -in k8s-node-2-worker.csr -CA k8sca.pem -CAkey k8sca-key.pem -CAcreateserial -out k8s-node-2-worker.pem -days 365 -extensions v3_req -extfile worker-openssl.cnf
</code></pre></td></tr></table></div></div><h2 id=生成集群管理证书>生成集群管理证书</h2><p>所有 node 生成以后， 还需要生成集群管理证书</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>openssl genrsa -out admin-key.pem 2048

openssl req -new -key admin-key.pem -out admin.csr -subj &#34;/CN=kube-admin&#34;

openssl x509 -req -in admin.csr -CA k8sca.pem -CAkey k8sca-key.pem -CAcreateserial -out admin.pem -days 365
</code></pre></td></tr></table></div></div><h2 id=apiserver-配置>apiserver 配置</h2><p>编辑 master apiserver 配置文件</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim /etc/kubernetes/apiserver


###
# kubernetes system config
#
# The following values are used to configure the kube-apiserver
#

# The address on the local server to listen to.
KUBE_API_ADDRESS=&#34;--insecure-bind-address=10.6.0.140 --insecure-bind-address=127.0.0.1&#34;

# The port on the local server to listen on.
KUBE_API_PORT=&#34;--secure-port=6443 --insecure-port=8080&#34;

# Port minions listen on
KUBELET_PORT=&#34;--kubelet-port=10250&#34;

# Comma separated list of nodes in the etcd cluster
KUBE_ETCD_SERVERS=&#34;--etcd-servers=http://10.6.0.140:2379,http://10.6.0.187:2379,http://10.6.0.188:2379&#34;

# Address range to use for services
KUBE_SERVICE_ADDRESSES=&#34;--service-cluster-ip-range=10.254.0.0/16&#34;

# default admission control policies
KUBE_ADMISSION_CONTROL=&#34;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota&#34;

# Add your own!
KUBE_API_ARGS=&#34;--tls-cert-file=/etc/kubernetes/cert/apiserver.pem --tls-private-key-file=/etc/kubernetes/cert/apiserver-key.pem --client-ca-file=/etc/kubernetes/cert/k8sca.pem --service-account-key-file=/etc/kubernetes/cert/apiserver-key.pem&#34;
</code></pre></td></tr></table></div></div><h2 id=controller-manager-配置>controller manager 配置</h2><p>接着编辑 controller manager 的配置</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim /etc/kubernetes/controller-manager

###
# The following values are used to configure the kubernetes controller-manager

# defaults from config and apiserver should be adequate

# Add your own!
KUBE_CONTROLLER_MANAGER_ARGS=&#34;--service-account-private-key-file=/etc/kubernetes/cert/apiserver-key.pem  --root-ca-file=/etc/kubernetes/cert/k8sca.pem --master=http://127.0.0.1:8080&#34;
</code></pre></td></tr></table></div></div><h2 id=重启-所有服务>重启 所有服务</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>systemctl restart kube-apiserver
systemctl restart kube-controller-manager
systemctl restart kube-scheduler

systemctl status kube-apiserver
systemctl status kube-controller-manager
systemctl status kube-scheduler
</code></pre></td></tr></table></div></div><h2 id=node-节点配置>node 节点配置</h2><p>先 copy 配置文件 到 node 节点</p><p>k8s-node-1 节点：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>mkdir /etc/kubernetes/cert/

# 必须授权

chown kube:kube -R /etc/kubernetes/cert

# 拷贝如下三个文件到 /etc/kubernetes/cert/ 目录下

k8s-node-1-worker-key.pem 
k8s-node-1-worker.pem
k8sca.pem

</code></pre></td></tr></table></div></div><p>k8s-node-2 节点：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>mkdir /etc/kubernetes/cert/

# 必须授权
chown kube:kube -R /etc/kubernetes/cert

# 拷贝如下三个文件到 /etc/kubernetes/cert/ 目录下
k8s-node-2-worker-key.pem 
k8s-node-2-worker.pem
k8sca.pem
</code></pre></td></tr></table></div></div><h2 id=node-节点-kubelet-配置>node 节点 kubelet 配置</h2><p>如下配置 所有 node 节点都需要配置</p><p>修改 kubelet 配置</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim /etc/kubernetes/kubelet


###
# kubernetes kubelet (minion) config

# The address for the info server to serve on (set to 0.0.0.0 or &#34;&#34; for all interfaces)
KUBELET_ADDRESS=&#34;--address=10.6.0.188&#34;

# The port for the info server to serve on
KUBELET_PORT=&#34;--port=10250&#34;

# You may leave this blank to use the actual hostname
KUBELET_HOSTNAME=&#34;--hostname-override=k8s-node-2&#34;

# location of the api-server
KUBELET_API_SERVER=&#34;--api-servers=https://10.6.0.140:6443&#34;

# Add your own!
KUBELET_ARGS=&#34;--tls-cert-file=/etc/kubernetes/cert/k8s-node-1-worker.pem --tls-private-key-file=/etc/kubernetes/cert/k8s-node-1-worker-key.pem --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml --pod-infra-container-image=docker.io/kubernetes/pause:latest&#34;
</code></pre></td></tr></table></div></div><h2 id=node-节点-config-配置>node 节点 config 配置</h2><p>修改 config 配置</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim /etc/kubernetes/config


###
# kubernetes system config
#
# The following values are used to configure various aspects of all
# kubernetes services, including
#
#   kube-apiserver.service
#   kube-controller-manager.service
#   kube-scheduler.service
#   kubelet.service
#   kube-proxy.service
# logging to stderr means we get it in the systemd journal
KUBE_LOGTOSTDERR=&#34;--logtostderr=true&#34;

# journal message level, 0 is debug
KUBE_LOG_LEVEL=&#34;--v=0&#34;

# Should this cluster be allowed to run privileged docker containers
KUBE_ALLOW_PRIV=&#34;--allow-privileged=false&#34;

# How the controller-manager, scheduler, and proxy find the apiserver
KUBE_MASTER=&#34;--master=https://10.6.0.140:6443&#34;
</code></pre></td></tr></table></div></div><h2 id=node-创建-kube-proxy>node 创建 kube-proxy</h2><p>创建 kube-proxy 配置文件</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim /etc/kubernetes/worker-kubeconfig.yaml


apiVersion: v1
kind: Config
clusters:
- name: local
  cluster:
    certificate-authority: /etc/kubernetes/cert/k8sca.pem
users:
- name: kubelet
  user:
    client-certificate: /etc/kubernetes/cert/k8s-node-1-worker.pem
    client-key: /etc/kubernetes/cert/k8s-node-1-worker-key.pem
contexts:
- context:
    cluster: local
    user: kubelet
  name: kubelet-context
current-context: kubelet-context
</code></pre></td></tr></table></div></div><h2 id=node-节点-配置-kube-proxy-证书>node 节点 配置 kube-proxy 证书</h2><p>配置 kube-proxy 使其使用证书</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>vim /etc/kubernetes/proxy


###
# kubernetes proxy config

# default config should be adequate

# Add your own!
KUBE_PROXY_ARGS=&#34;--master=https://10.6.0.140:6443 --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml&#34;
</code></pre></td></tr></table></div></div><h2 id=node节点重启服务>node节点重启服务</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>systemctl restart kubelet
systemctl restart kube-proxy

systemctl status kubelet
systemctl status kube-proxy
</code></pre></td></tr></table></div></div><p>至此，整个集群已经搭建完成，剩下的就是pod 的测试</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2016-10-12</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md><span><a class=link-to-markdown href=/kubernetes-1.3.8/index.md target=_blank>阅读原始文档</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=https://jicki.cn/kubernetes-1.3.8/ data-title="docker k8s 1.3.8 + flannel" data-via=jicki234><i class="fab fa-twitter fa-fw"></i></a><a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://jicki.cn/kubernetes-1.3.8/><i class="fab fa-facebook-square fa-fw"></i></a><a href=javascript:void(0); title="分享到 WhatsApp" data-sharer=whatsapp data-url=https://jicki.cn/kubernetes-1.3.8/ data-title="docker k8s 1.3.8 + flannel" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href=javascript:void(0); title="分享到 Line" data-sharer=line data-url=https://jicki.cn/kubernetes-1.3.8/ data-title="docker k8s 1.3.8 + flannel"><i data-svg-src=/lib/simple-icons/icons/line.min.svg></i></a><a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://jicki.cn/kubernetes-1.3.8/ data-title="docker k8s 1.3.8 + flannel"><i class="fab fa-weibo fa-fw"></i></a><a href=javascript:void(0); title="分享到 Myspace" data-sharer=myspace data-url=https://jicki.cn/kubernetes-1.3.8/ data-title="docker k8s 1.3.8 + flannel" data-description="docker k8s 1.3.8 + flannel"><i data-svg-src=/lib/simple-icons/icons/myspace.min.svg></i></a><a href=javascript:void(0); title="分享到 Blogger" data-sharer=blogger data-url=https://jicki.cn/kubernetes-1.3.8/ data-title="docker k8s 1.3.8 + flannel" data-description="docker k8s 1.3.8 + flannel"><i class="fab fa-blogger fa-fw"></i></a><a href=javascript:void(0); title="分享到 Evernote" data-sharer=evernote data-url=https://jicki.cn/kubernetes-1.3.8/ data-title="docker k8s 1.3.8 + flannel"><i class="fab fa-evernote fa-fw"></i></a></span></div></div></div><div class=post-info-more><section class=post-tags></section><section><span><a href=javascript:void(0); onclick=window.history.back();>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/glusterfs/ class=prev rel=prev title="CentOS 7 安装 GlusterFS"><i class="fas fa-angle-left fa-fw"></i>CentOS 7 安装 GlusterFS</a>
<a href=/kubernetes-1.4.0/ class=next rel=next title="docker kubernetes 1.4 部署">docker kubernetes 1.4 部署<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments><div id=valine class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://valine.js.org/>Valine</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>由 <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.73.0">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i>LoveIt</a></div><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2020</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=https://jicki.cn target=_blank>小炒肉</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span><span class=icp-splitter>&nbsp;|&nbsp;</span><br class=icp-br><span class=icp>粤ICP备20055633号</span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title=回到顶部><i class="fas fa-arrow-up fa-fw"></i></a><a href=# id=view-comments class=fixed-button title=查看评论><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=/lib/valine/valine.min.css><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/katex/copy-tex.min.css><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><script type=text/javascript src=/lib/valine/Valine.min.js></script><script type=text/javascript src=/lib/smooth-scroll/smooth-scroll.min.js></script><script type=text/javascript src=/lib/autocomplete/autocomplete.min.js></script><script type=text/javascript src=/lib/lunr/lunr.min.js></script><script type=text/javascript src=/lib/lunr/lunr.stemmer.support.min.js></script><script type=text/javascript src=/lib/lunr/lunr.zh.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js></script><script type=text/javascript src=/lib/katex/auto-render.min.js></script><script type=text/javascript src=/lib/katex/copy-tex.min.js></script><script type=text/javascript src=/lib/katex/mhchem.min.js></script><script type=text/javascript src=/lib/cookieconsent/cookieconsent.min.js></script><script type=text/javascript>window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":50},"comment":{"valine":{"appId":"1LTTCvDe4Nt8XSdFzejtUsVF-gzGzoHsz","appKey":"cvpPM7sbgOw0pTXbh6YVKrjc","avatar":"mp","el":"#valine","emojiCDN":"https://cdn.jsdelivr.net/npm/emoji-datasource-google@5.0.1/img/google/64/","emojiMaps":{"100":"1f4af.png","alien":"1f47d.png","anger":"1f4a2.png","angry":"1f620.png","anguished":"1f627.png","astonished":"1f632.png","black_heart":"1f5a4.png","blue_heart":"1f499.png","blush":"1f60a.png","bomb":"1f4a3.png","boom":"1f4a5.png","broken_heart":"1f494.png","brown_heart":"1f90e.png","clown_face":"1f921.png","cold_face":"1f976.png","cold_sweat":"1f630.png","confounded":"1f616.png","confused":"1f615.png","cry":"1f622.png","crying_cat_face":"1f63f.png","cupid":"1f498.png","dash":"1f4a8.png","disappointed":"1f61e.png","disappointed_relieved":"1f625.png","dizzy":"1f4ab.png","dizzy_face":"1f635.png","drooling_face":"1f924.png","exploding_head":"1f92f.png","expressionless":"1f611.png","face_vomiting":"1f92e.png","face_with_cowboy_hat":"1f920.png","face_with_hand_over_mouth":"1f92d.png","face_with_head_bandage":"1f915.png","face_with_monocle":"1f9d0.png","face_with_raised_eyebrow":"1f928.png","face_with_rolling_eyes":"1f644.png","face_with_symbols_on_mouth":"1f92c.png","face_with_thermometer":"1f912.png","fearful":"1f628.png","flushed":"1f633.png","frowning":"1f626.png","ghost":"1f47b.png","gift_heart":"1f49d.png","green_heart":"1f49a.png","grimacing":"1f62c.png","grin":"1f601.png","grinning":"1f600.png","hankey":"1f4a9.png","hear_no_evil":"1f649.png","heart":"2764-fe0f.png","heart_decoration":"1f49f.png","heart_eyes":"1f60d.png","heart_eyes_cat":"1f63b.png","heartbeat":"1f493.png","heartpulse":"1f497.png","heavy_heart_exclamation_mark_ornament":"2763-fe0f.png","hole":"1f573-fe0f.png","hot_face":"1f975.png","hugging_face":"1f917.png","hushed":"1f62f.png","imp":"1f47f.png","innocent":"1f607.png","japanese_goblin":"1f47a.png","japanese_ogre":"1f479.png","joy":"1f602.png","joy_cat":"1f639.png","kiss":"1f48b.png","kissing":"1f617.png","kissing_cat":"1f63d.png","kissing_closed_eyes":"1f61a.png","kissing_heart":"1f618.png","kissing_smiling_eyes":"1f619.png","laughing":"1f606.png","left_speech_bubble":"1f5e8-fe0f.png","love_letter":"1f48c.png","lying_face":"1f925.png","mask":"1f637.png","money_mouth_face":"1f911.png","nauseated_face":"1f922.png","nerd_face":"1f913.png","neutral_face":"1f610.png","no_mouth":"1f636.png","open_mouth":"1f62e.png","orange_heart":"1f9e1.png","partying_face":"1f973.png","pensive":"1f614.png","persevere":"1f623.png","pleading_face":"1f97a.png","pouting_cat":"1f63e.png","purple_heart":"1f49c.png","rage":"1f621.png","relaxed":"263a-fe0f.png","relieved":"1f60c.png","revolving_hearts":"1f49e.png","right_anger_bubble":"1f5ef-fe0f.png","robot_face":"1f916.png","rolling_on_the_floor_laughing":"1f923.png","scream":"1f631.png","scream_cat":"1f640.png","see_no_evil":"1f648.png","shushing_face":"1f92b.png","skull":"1f480.png","skull_and_crossbones":"2620-fe0f.png","sleeping":"1f634.png","sleepy":"1f62a.png","slightly_frowning_face":"1f641.png","slightly_smiling_face":"1f642.png","smile":"1f604.png","smile_cat":"1f638.png","smiley":"1f603.png","smiley_cat":"1f63a.png","smiling_face_with_3_hearts":"1f970.png","smiling_imp":"1f608.png","smirk":"1f60f.png","smirk_cat":"1f63c.png","sneezing_face":"1f927.png","sob":"1f62d.png","space_invader":"1f47e.png","sparkling_heart":"1f496.png","speak_no_evil":"1f64a.png","speech_balloon":"1f4ac.png","star-struck":"1f929.png","stuck_out_tongue":"1f61b.png","stuck_out_tongue_closed_eyes":"1f61d.png","stuck_out_tongue_winking_eye":"1f61c.png","sunglasses":"1f60e.png","sweat":"1f613.png","sweat_drops":"1f4a6.png","sweat_smile":"1f605.png","thinking_face":"1f914.png","thought_balloon":"1f4ad.png","tired_face":"1f62b.png","triumph":"1f624.png","two_hearts":"1f495.png","unamused":"1f612.png","upside_down_face":"1f643.png","weary":"1f629.png","white_frowning_face":"2639-fe0f.png","white_heart":"1f90d.png","wink":"1f609.png","woozy_face":"1f974.png","worried":"1f61f.png","yawning_face":"1f971.png","yellow_heart":"1f49b.png","yum":"1f60b.png","zany_face":"1f92a.png","zipper_mouth_face":"1f910.png","zzz":"1f4a4.png"},"enableQQ":false,"highlight":true,"lang":"zh-cn","pageSize":10,"placeholder":"你的评论 ...","recordIP":true,"visitor":true}},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","lunrLanguageCode":"zh","lunrSegmentitURL":"/lib/lunr/lunr.segmentit.js","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"lunr"}};</script><script type=text/javascript src=/js/theme.min.js></script></body></html>